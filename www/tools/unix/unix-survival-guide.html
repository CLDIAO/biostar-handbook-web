{% extends "unitbase.html" %}
{% load pytags %}
{# title =  Unix #}
{# subtitle = survival guide #}
{# name = A bioinformatician's command line survival guide  #}

{% block body %}

{% markdown %}

#### 1: Use sequence aware tools!

Unix tools are generic text processing tools. They are great to produce
quick evaluations. Be careful in how you use them. For example the following way
to find the length of a sequence is incorrect:

    cat reference.fa | grep -v ">" | wc -c

This counts more than just the number of nucleotides in the sequence file `reference.fa`.
It will also count the new lines character the end of each line. You should use a sequence
aware tool like bioawk:

    cat reference.fa | bioawk -c fastx ' { print length($seq) } '

Or a simpler and potentially faster way to find the lengths of **all** sequences in a file:

    # Creates a simple index file
    samtools faidx reference.fa
    more reference.fa.fai

- - -
#### 2: grep (and other matchers) find matches on the entire input line

Grep is a pattern matcher it will match the pattern anywhere on the line.
It is very easy to match more than what you intended. The error of matching more is a lot harder to notice than the error or matching less than needed.

For anything but the simplest patterns use `egrep` and build `regular expressions` that describe
the boundaries (anchors) of the match.

    # Wrong pattern
    # Which gff line contains the value 62. It could match 162 or 621 as well.
    cat data.gff | grep '62'

    # The value of 62 anchored on the left and right by tabs.
    cat data.gff | egrep '\t62\t`

- - -
#### 3. Beyond grep: ack

Finding content in files can be tedious. While grep searches a single file we
often want to find content where we don't know the file that might contain the information.
We could combine a `find` and `grep` like so:

    # Search with grep for the word bwa in all the files of a subdirectory
    grep bwa $(find . -type f)

The first tool that brough santiy to this was called `ack`. The above command turns into:

    # With ack
    ack bwa

Installation:

    brew install ack

For more details and installation on other platforms visit [Beyond Grep][ack]. Over time
a number of similar but faster
tools have been released, but these have more complex installations [ag: silver searcher][ag] and [Sift][sift]

[ack]: http://beyondgrep.com/
[ag]: http://geoff.greer.fm/ag/
[sift]: https://sift-tool.org/info.html

- - -
#### 4. There is a wide range of unix like tools

Get a good sense of what each of the following tools do:

* `bioawk` - bioinformatics aware awk
* `seqtk` - sequence manipulation toolkit: extract random sample, transform sequences, trim etc
* `tabtk` - tab toolkit, the missing compomnents from unix `cut`
* `tabix` - interval query of large tabular files.

Note: all the above software were written  by Heng Li.

#### 5. Advanced data processing at command line tools: Miller, csvkit

These tools feel like one step away from being a full fledged programming languages.
Are a lot more powerful than basic Unix tools but require learning a local and specific
rules for that tool. You can do marvelous data analytics with them.

* [Miller][miller] is like sed, awk, cut, join, and sort for name-indexed data such as CSV.
* [csvkit][csvkit] a suite of utilities for converting to and working with CSV and tabular data

[csvkit]: https://csvkit.readthedocs.org
[miller]: http://johnkerl.org/miller/doc/index.html

{% endmarkdown %}

{% endblock %}
