{% extends "unitbase.html" %}
{% load pytags %}
{# title = Genome Assemblies #}
{# subtitle = building new genomes #}
{# name = Genome Assemblies. Building new genomes #}

{% block body %}

{% markdown %}
### Genome Assembly


Genome assembly is more of an art and an exercise of trial and error.
Multiple parameter settings need to be explored,

Assemblers are also more impenetrable in the way they work than aligners.
They often feel like a black box that we have little control over.

    # Obtain the sequencing data
    fastq-dump SRR1553425 -X 100000 --split-files

    # For assembling genomes high quality data is important
    # to avoid creating dead ens.
    trimmomatic PE -baseout trimmed.fq SRR1553425_1.fastq SRR1553425_2.fastq  SLIDINGWINDOW:4:30 MINLEN:35 TRAILING:3

    # Build hashes of size 31
    # Puts the results into directory d31
    velveth d31 31 -fastq  -short trimmed_1P.fq

    # Look at what files have been created.
    ls d31

    # Use velvetg to assemble the genome hashed into directory d31.
    # The automatic covertage cutoff computation should produce the ideal parameters
    velvetg d31  -cov_cutoff auto

    # Produces the output:
    # Final graph has 8231 nodes and n50 of 26, max 240, total 97122, using 0/90977 reads

    # But the results above are blatantly wrong. The N50 is 24!!!! that is
    # obviously and blatantly wrong. After all the read lenght is 100bp! Why did we end up with
    # a genome build size that is less than the read lenght????
    # That will stay a mystery I am afraid.

    # Still look at what new files have been created there.
    ls d31

    #
    # We need to tune velvetg and figure out the right cutoff.
    # Basically we are rerunning it and observing what happens
    #
    velvetg d31 -cov_cutoff 5
    # Final graph has 1038 nodes and n50 of 28, max 310, total 27557, using 0/90977 reads

    velvetg d31 -cov_cutoff 10
    # Final graph has 320 nodes and n50 of 232, max 1115, total 21339, using 0/90977 reads

    velvetg d31 -cov_cutoff 50
    # Final graph has 5 nodes and n50 of 6049, max 7919, total 18731, using 0/90977 reads

    velvetg d31 -cov_cutoff 100
    # Final graph has 1 nodes and n50 of 18515, max 18515, total 18515, using 0/90977 reads

Whoa! Jackpot! This last parameter works better than anyone would have imagined.
It produces just one node, meaning the entire virus and the maximum lenght is right there with the
expected genome size.

But sometimes we can't afford to rerun with so many alternatives. Could we figure out the
cutoff ourselves? The has directory has tracking files in them `d31`

    more d31/stats.txt

Note how above we could hash genomes at different sizes 41, 51 etc and redo
the assembly. There is a connection (and tradeoff) between the hash size
and the performance of the assembler.

Visualize the resulting contig file:

    # Create an alignment from the contigs that you got.
    # For each run of velvetg at different cutoff create an alignment
    alias sam2bam='samtools view -b - | samtools sort'
    bwa mem ~/refs/ebola/1976.fa d31/contigs.fa | sam2bam > align100.sam
    samtools index align100.sam

Below we show the contigs generated at different assembly cutoffs (20, 50, 100):

{% img "img/assembly_intro_1.png" css="img-responsive"  %}

{%  endmarkdown %}

{% endblock %}
